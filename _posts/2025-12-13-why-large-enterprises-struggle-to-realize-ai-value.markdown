---
layout: single
title: "Why Large Enterprises Struggle to Realize AI Value"
excerpt: "AI can do way more than most people realize. The opportunity goes beyond efficiency - it's about new capabilities and real business growth. Here's what it takes to actually capture that value."
category: "AI Strategy & Leadership"
featured: true
---

A friend asked me a question on LinkedIn that I couldn't answer in a comment:

![LinkedIn question about enterprise AI adoption](/docs/assets/images/enterprise-ai-struggle/linkedin-question.png)

There's a lot packed into that question, and the short answer is yes - many enterprises aren't looking at it right. But the longer answer involves understanding why, and it's not just one thing. It's incentives, culture, organizational structure, and shallow exposure all reinforcing each other.

## Why This Is Hard

In any large enterprise, change is always going to be hard. The larger you get, the fewer incentives there are to take risks - the innovator's dilemma isn't a new concept. There's that old saying about how you won't get fired for choosing Oracle as your database. If you push for something new and it fails, you pay the price personally and politically. If you stick with the safe choice and it's mediocre, nobody notices.

Enterprises are adopting AI - [the studies confirm it](https://cdn.openai.com/pdf/7ef17d82-96bf-4dd1-9df2-228f7f377a29/the-state-of-enterprise-ai_2025-report.pdf). But adoption is different from depth. Having a ChatGPT enterprise license is different from fundamentally changing how work gets done.

The only way to get a feel for what these tools are capable of is to have people in the weeds experimenting. It's not enough for an executive to say "we're going to leverage AI" and have that show up in a PowerPoint deck - that doesn't mean anything unless people are actually trying things, being curious, and digging in.

## What Has to Change

Executive buy-in has to be concrete, not just words. You can't just say it, you have to incentivize it. The people doing the work need real permission and real motivation to use these tools.

Look at what Shopify did. Tobi LÃ¼tke didn't just send a memo saying AI is important - [he spelled out concrete expectations](https://x.com/tobi/status/1909251946235437514). Build your prototype with AI. Your performance will reflect how well you use these tools. You can't add headcount until you've shown AI can't handle it. They have a leaderboard showing who's using AI the most. It's visible and public.

Those are real levers. If your performance systems still reward "avoid risk" and "don't break process," AI adoption will stay shallow.

People also need time. Organizations often give people one or two training days per year and treat it like an event rather than ongoing practice. That's not enough. There's no time to learn how to change how you do the work if people are too busy doing the work itself. But if you hire curious people and give them time, it's actually not that difficult to learn.

Here's another issue: when different groups use these tools, it changes the work they're capable of doing. Before AI, if you're an engineer without design skills, it was hard to do nuanced design work. Now you can get much further. If your core skill is writing marketing copy, you can now also produce draft graphics. These tools change people's coverage area.

This is disruptive for larger organizations that have established how different units work together. When those boundaries break down implicitly, it can be frightening. Instead of figuring out how to use the tools together, people might spend energy fighting political battles about who owns what.

The organizations I've seen use these tools best are the smallest ones - high curiosity, high agency, very low ego. Large companies can't just "be small." So leadership has to name the disruption rather than pretend it isn't happening, and then actually come up with a clear plan to change with it.

## What's Actually Possible

When someone says AI is just an efficiency play, my view is they haven't spent enough time with the technology. Efficiency means something different to me than to them at this point - I'd bet the detail, complexity, and amount of work I'm getting done with these tools is pretty different from what they're picturing.

When people talk about the "efficiency play," they're usually thinking about the basic ChatGPT 1.0 use cases - editing an email, spell-checking, generating ideas. And if that's what efficiency means to you, then sure, that's not that exciting.

But these tools are shockingly good now. Here's a small set of examples to give you a feel if you haven't been deep in this space yet:

- You can [take a scanned book and turn it into a polished PowerPoint deck](/2025/12/10/what-ai-can-actually-do-now.html).
- This might sound ridiculous, but researchers are [using AI and a smartphone to decode dolphin communication](https://blog.google/technology/ai/dolphingemma/).
- Someone asked GPT-5 Pro to [research top AI offerings and create a feature comparison](https://x.com/_simonsmith/status/1999818002397585530) - it produced a detailed workbook:

![GPT-5 Pro creating a detailed AI feature comparison workbook](/docs/assets/images/enterprise-ai-struggle/gpt5-pro.png)

That last one is worth pausing on. GPT-5 Pro costs $200 a month. Most people won't pay that, which means most people have no idea what the frontier actually looks like.

AI can just do things now, and it can do a lot of things. Anthropic publishes a [use cases page](https://www.claude.com/resources/use-cases) with dozens of examples - they give you the prompts to try and walk you through how to do it. If you spent an hour going through it, you'd probably be shocked at what's already possible. But most people don't spend that time.

Here's a fun toy example I tried this week. It's not practical, but when I show things like this to people, the reaction is usually "okay, that's wild." My wife drew this while we were sketching with the kids:

![Pencil sketch input](/docs/assets/images/enterprise-ai-struggle/input.jpg)

I uploaded it to Nano Banana Pro and asked it to make it realistic while keeping all the details:

![Realistic output from Nano Banana Pro](/docs/assets/images/enterprise-ai-struggle/output.png)

It kept all the detail - the igloo, the penguin, the zebra, the parrot, the pig. Playing around with stuff like this is how you build intuition for what's possible, and that intuition is table stakes. Without it, you're not going to see how these tools apply to your own work or to the products you're building.

Here's what it looks like when a company actually understands the capabilities and applies them to a real problem - not just an efficiency play, but something that expands their revenue. Gavin Baker was talking on a [recent episode of Invest Like the Best](https://joincolossus.com/episode/nvidia-v-google-the-economics-of-ai/) about C.H. Robinson, a freight forwarder. Their AI use case focused on quoting price and availability to customers. Before AI, when a customer called with a request - urgently needing three 18-wheelers from Chicago to Denver - it would take 15 to 45 minutes, and they were only quoting 60% of inbound requests. With AI, they're now quoting 100% of requests in seconds.

That's a shocking change. It impacted their revenue and cost lines, resulted in a great quarter, and their stock went up 20%. This is a Fortune 500 company outside tech with real numbers showing what AI did for them.

Here's an interesting twist. I wanted to include those specific stats in this post, but I'd forgotten the details. Guess how I found them? I put the YouTube video into NotebookLM and asked:

![Using NotebookLM to research AI use cases](/docs/assets/images/enterprise-ai-struggle/gavin-baker.png)

This is how thinking about AI works for me now - it's always a thread. I have a problem, I reach for a tool, and it's become second nature. Are you using AI like this? Is your leadership?

## The Hard Truths

I want to be clear - there are leaders out there genuinely trying to do the right things here. And this technology is a really big change. Change is hard. It can be jarring, especially when people disagree with the ethics of it or are fearful of how it's going to reshape their work. I get that.

But some people aren't going to get on the boat. That's just reality. And my view, given what I've seen - this might sound harsh - but you've got to burn it down. If you have something that gives you an edge when used right, you can't spend a bunch of effort convincing people who refuse to try. Yes, you have to put the right structure together. But ultimately, if you can't get people on board, they have to be off of it.

This is one of the first times it's actually felt that way to me. In the past, as a leader, I've been much more about bringing people along. But this technology is going to make companies die from the innovator's dilemma faster than ever before. The leverage gap is too large. And when I tell people this, sometimes they look at me with raised eyebrows like I'm crazy, but it has never been easier for massive companies to be disrupted by small teams who know how to use these tools.

If you're an executive and you're scared about AI, and you're putting in PowerPoints that your company is leveraging AI, but you need to put more meat on the bones - where do you start? Have you tried to use AI yourself? Do you use it every day? Have you tried to vibe code something yourself, even something simple? If the answer is no, that's where you start.

Stop reading [the study about how 95% of generative AI pilots are failing](/2025/08/24/the-real-reasons-genai-pilots-fail.html). That's not going to make you more equipped to lead. Go actually try something. Look at what Aaron Levie is doing at Box, what Tobi is doing at Shopify. There's no shortage of resources showing what's actually working for enterprises - [OpenAI publishes case studies](https://cdn.openai.com/business-guides-and-resources/from-experiments-to-deployments_whitepaper_11-25.pdf), and there are plenty of others. You're likely to find inspiration you can apply to your own problems.

## What You Can Actually Do

If you're in a position to influence this at your company, here's the short playbook:

- **Use AI yourself, every day.** You can't lead this if you don't understand it. Pay for a subscription - if you really want to explore, pay for the highest tier for a month and see what happens. And don't give it simple tasks. Give it the hardest thing you have to do that week. Time box it to 30 minutes if you want, but throw your hardest problem at it. You need to understand the frontier of what's possible, not just what always works.
- **Start with pain points, not "AI projects."** Don't go looking for places to use AI. Look at what's frustrating people, what's slow, what's expensive. Then see if AI helps. That's a very different starting point.
- **Actually change the incentives.** Put AI usage in performance reviews. Make it visible. If your systems still reward "don't break anything," adoption will stay shallow.
- **Give people time to learn.** Not a training day. Real, ongoing time to experiment and get reps in.
- **Share what's working.** When someone figures something out, tell people. Small wins build momentum and give others permission to try.
- **Look at your customers' problems.** What couldn't you solve before because the tools didn't exist? That's where the real value is.
- **Make time to learn.** This space moves fast. You don't need to be on the bleeding edge, but you need to spend real time yourself understanding what's changing. [The AI Daily Brief](https://podcasts.apple.com/us/podcast/the-ai-daily-brief-artificial-intelligence-news/id1680633614) is a good place to start - find the 10 most popular episodes from the last six months and listen to them all.

## Back to My Friend's Question

Are enterprises looking at this wrong? Yes, but maybe not just in the way you'd expect. It's not only about misunderstanding the value. It's about misunderstanding what it takes to actually capture that value.

On the technical side, people need real time to understand what these tools can do. And they need to make the connection between those capabilities and the problems their customers actually have - not just efficiency gains, but new ways to grow the business.

On the organizational side, have they thought about whether they need to fundamentally reshape how their teams are organized? Have they thought about empowering people on the ground level to come up with ideas more than ever before? The companies that get this right will need to get both sides right - the technology and the organizational change that comes with it.

There's a lot to change here. The gap between companies that figure this out and companies that don't is going to get wide fast.
