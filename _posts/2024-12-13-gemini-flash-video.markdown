---
layout: single
title: "Gemini 2.0 Flash: A Shift in How We Interact with AI"
---

This week, Google released [Gemini 2.0 Flash](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/), which introduces two standout features. You can share your screen or a video in real time and interact with the model about what it’s seeing. You can also use your webcam to engage with the model, letting it "see" you and respond based on visual context.  

These aren’t just incremental updates. They highlight two big trends happening simultaneously. First, the underlying capabilities of these models are improving rapidly, enabling far more sophisticated interactions. Second, we’re improving how these tools integrate into real human workflows. Designing effective UX patterns is going to be critical, and tools like Gemini Flash give us a glimpse of what’s possible.  

## See It in Action  

Here’s a really compelling way to see this in action: [a demo from a radiologist at the University of Toronto](https://x.com/RajeshBhayana_/status/1867329568404652253). In the video, the radiologist uses Gemini Flash to analyze a CT scan of an abdomen, asking detailed questions and receiving insights in real time.  
 
This isn’t about replacing the work of analyzing a scan — it’s more like having a highly capable assistant alongside you. Watching the interaction makes it clear how these tools are evolving to complement human expertise.

And it’s not just this one example. Tons of other demos are being generated, showing how people are solving real problems with this kind of technology.  

## Try It Yourself  

You can try Gemini Flash for free right now. Head over to [Google AI Studio Live](https://aistudio.google.com/live) to share your screen, talk to the model, and explore its potential. Testing it on your own problems is the best way to understand how it can work for you.  

These tools aren’t just for radiologists or highly specialized use cases. They’re flexible enough to test across a range of workflows, and experimenting hands-on is the fastest way to see what’s possible.  

## Why It Matters  

Things in AI are moving incredibly fast, and tools like this highlight how much the way we interact with technology is changing. It’s not just about what these models can do — it’s about how we engage with them and make them work for us.  

As someone who’s worked on integrating AI tools into workflows, I see these changes as both exciting and challenging. The real opportunity lies in figuring out how to connect these capabilities with practical needs.  

If you’re curious, start by watching the [radiologist’s demo](https://x.com/RajeshBhayana_/status/1867329568404652253). Then head over to [Google AI Studio Live](https://aistudio.google.com/live) and try Gemini Flash for yourself. There’s no need to overthink it — just experiment and see how it fits into your workflow.  
